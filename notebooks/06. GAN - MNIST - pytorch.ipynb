{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title imports\n",
    "from tensorboardX import SummaryWriter\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "import functools\n",
    "import numpy as np\n",
    "import time\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title func: get_dataloader\n",
    "def get_dataloader(dataset, batch_size: int = 16, shuffle: bool = True) -> DataLoader:\n",
    "  return DataLoader(\n",
    "      dataset=dataset,\n",
    "      batch_size=batch_size,\n",
    "      shuffle=shuffle\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 60000 ; 1875 batches\n",
      "Test samples: 10000 ; 313 batches\n"
     ]
    }
   ],
   "source": [
    "#@title Load the datasets and create dataloaders\n",
    "batch_size = 32  #@param\n",
    "shuffle = True  #@param\n",
    "download = True  #@param\n",
    "\n",
    "image_transforms = transforms.Compose([\n",
    "  transforms.Pad(padding=2, fill=0, padding_mode=\"constant\"),\n",
    "  transforms.ToTensor(),\n",
    "  transforms.Normalize((0.5), (.5)),\n",
    "])\n",
    "\n",
    "dataset_train = MNIST(root=\"data/MNIST/train\", train=True, download=download, transform=image_transforms)\n",
    "dataset_test = MNIST(root=\"data/MNIST/test\", train=False, download=download, transform=image_transforms)\n",
    "\n",
    "dataloader_train = get_dataloader(dataset_train, batch_size=batch_size, shuffle=shuffle)\n",
    "dataloader_test = get_dataloader(dataset_test, batch_size=batch_size, shuffle=shuffle, )\n",
    "\n",
    "print(f\"Train samples: {len(dataset_train)} ; {len(dataloader_train)} batches\")\n",
    "print(f\"Test samples: {len(dataset_test)} ; {len(dataloader_test)} batches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.7892) tensor(0.5592)\n",
      "tensor(-1.) tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "print(dataset_train[0][0].mean(), dataset_train[0][0].std())\n",
    "print(dataset_train[1][0].min(), dataset_train[1][0].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title classes: Encoder, CNNDiscriminator\n",
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, n_c_in, n_c_out, p_dropout=0):\n",
    "        super().__init__()\n",
    "        self.b1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(n_c_in, n_c_out, kernel_size=3, stride=1, padding=1),\n",
    "            # torch.nn.BatchNorm2d(n_c_out),\n",
    "            torch.nn.LeakyReLU(0.2),\n",
    "            torch.nn.Dropout(p_dropout),\n",
    "        )\n",
    "        # self.b2 = torch.nn.Sequential(\n",
    "        #     torch.nn.Conv2d(n_c_out, n_c_out, kernel_size=3, stride=1, padding=1),\n",
    "        #     torch.nn.BatchNorm2d(n_c_out),\n",
    "        #     torch.nn.ReLU(inplace=True),\n",
    "        #     torch.nn.Dropout(p_dropout),\n",
    "        # )\n",
    "        # self.b3 = torch.nn.Sequential(\n",
    "        #     torch.nn.Conv2d(n_c_out, n_c_out, kernel_size=3, stride=1, padding=1),\n",
    "        #     torch.nn.BatchNorm2d(n_c_out),\n",
    "        #     torch.nn.ReLU(inplace=True),\n",
    "        #     torch.nn.Dropout(p_dropout),\n",
    "        # )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out1 = self.b1(x)\n",
    "        return out1\n",
    "        # r1 = out1  # no residual since input is different size\n",
    "        # out2 = self.b2(r1)\n",
    "        # r2 = r1 + out2\n",
    "        # out3 = self.b3(r2)\n",
    "        # r3 = r2 + out3\n",
    "        # return r3\n",
    "\n",
    "class CNNDiscriminator(torch.nn.Module):\n",
    "  \"\"\"\n",
    "  A very simple CNN with \"resnet\" style blocks (not even sure if they truly are)\n",
    "  \"\"\"\n",
    "  def __init__(self, n_channels, n_classes):\n",
    "    super().__init__()\n",
    "    self.encoder1 = Encoder(n_channels, 16)\n",
    "    self.encoder2 = Encoder(16, 32)\n",
    "    self.encoder3 = Encoder(32, 64)\n",
    "    self.classifier = torch.nn.Linear(16 * 64, n_classes)\n",
    "\n",
    "  @staticmethod\n",
    "  def _encode_and_pool(encoder, inputs):\n",
    "    encoded = encoder(inputs)\n",
    "    pooled = torch.nn.functional.max_pool2d(encoded, kernel_size=2, stride=2)\n",
    "    return encoded, pooled\n",
    "\n",
    "  def forward(self, x):\n",
    "    encoded1, pooled1 = self._encode_and_pool(self.encoder1, x)\n",
    "    encoded2, pooled2 = self._encode_and_pool(self.encoder2, pooled1)\n",
    "    encoded3, pooled3 = self._encode_and_pool(self.encoder3, pooled2)\n",
    "    activations = self.classifier(pooled3.view(pooled3.shape[0], -1))\n",
    "    probs = torch.nn.functional.softmax(activations, dim=-1)\n",
    "    log_probs = torch.nn.functional.log_softmax(activations, dim=-1)\n",
    "    return log_probs, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "  device = \"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33546 parameters\n",
      "torch.Size([32, 1, 32, 32]) torch.Size([32])\n",
      "torch.Size([32, 10])\n"
     ]
    }
   ],
   "source": [
    "#@title MNIST model,loss,optim\n",
    "model_mnist = CNNDiscriminator(1, 10).to(device)\n",
    "n_params = sum([np.prod(param.size()) for param in model_mnist.parameters()])\n",
    "print(f\"{n_params} parameters\")\n",
    "\n",
    "# Test the model\n",
    "images, labels = next(iter(dataloader_train))\n",
    "print(images.shape, labels.shape)\n",
    "_, pred_probs = model_mnist(images.to(device))\n",
    "print(pred_probs.shape)\n",
    "\n",
    "# Loss & optim\n",
    "loss_mnist = torch.nn.NLLLoss().to(device)\n",
    "optimizer_mnist = torch.optim.Adam(params=model_mnist.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title visualizing funcs\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from skimage.util import montage\n",
    "\n",
    "\n",
    "# def show_img(im, figsize=None, ax=None, title=None):\n",
    "#     import matplotlib.pyplot as plt\n",
    "#     if not ax: fig, ax = plt.subplots(figsize=figsize)\n",
    "#     ax.imshow(im, cmap='gray')\n",
    "#     if title is not None: ax.set_title(title, fontsize=50)\n",
    "#     ax.get_xaxis().set_visible(False)\n",
    "#     ax.get_yaxis().set_visible(False)\n",
    "#     return ax\n",
    "\n",
    "\n",
    "# def draw_rect(ax, bbox, edgecolor='red'):\n",
    "#     import matplotlib.patches as patches\n",
    "#     x, y, w, h = bbox\n",
    "#     patch = ax.add_patch(patches.Rectangle((x, y), w, h, fill=False, edgecolor=edgecolor, lw=2))\n",
    "\n",
    "\n",
    "# def draw_canvas(img, bboxes: np.ndarray, color='red'):\n",
    "#     fig, ax = plt.subplots(1, 1, figsize=(192 / 20, 108 / 20))\n",
    "\n",
    "#     for ix in range(len(bboxes)):\n",
    "#         bbox = bboxes[ix]\n",
    "\n",
    "#         draw_rect(ax, bbox, edgecolor=color)  # will add red bounding boxes for each character\n",
    "\n",
    "#     ax = show_img(img, ax=ax)\n",
    "#     plt.xticks([])\n",
    "#     plt.yticks([])\n",
    "\n",
    "\n",
    "# def visualize_data(dataloader, n=5, fields_to_print=None):\n",
    "#     for ix, data in enumerate(dataloader):\n",
    "#         if ix >= n:\n",
    "#             break\n",
    "\n",
    "#         img = data[\"image\"][0].data.cpu().numpy().transpose(1, 2, 0)\n",
    "#         dist = data[\"dists\"][0].data.cpu().numpy().astype(np.uint8)\n",
    "#         word = data[\"labels\"][0].data.cpu().numpy().astype(np.float32)\n",
    "\n",
    "#         if fields_to_print is not None:\n",
    "#             for field in fields_to_print:\n",
    "#                 print(data[field])\n",
    "\n",
    "#         # Remove the -100s in the padding\n",
    "#         pad_idx = np.where(word == -100)\n",
    "#         dist[pad_idx] = MAX_DIST - 1\n",
    "#         word[pad_idx] = 0\n",
    "\n",
    "#         print(img.shape, dist.shape)\n",
    "#         plt.figure(figsize=(20, 5))\n",
    "#         plt.imshow(img.astype(np.uint8))\n",
    "#         plt.show()\n",
    "#         plt.figure(figsize=(20, 5))\n",
    "#         plt.title(np.unique(dist))\n",
    "#         plt.imshow(dist.astype(np.uint8))\n",
    "#         plt.show()\n",
    "#         plt.figure(figsize=(20, 5))\n",
    "#         plt.title(np.unique(word))\n",
    "#         plt.imshow(word.astype(np.float32))\n",
    "#         plt.show()\n",
    "#         print('--------------')\n",
    "\n",
    "\n",
    "# def visualize_data_outputs(images, target_label, target_dist, pred_labels, pred_dists):\n",
    "#     pad_idxs = np.where(target_dist == -100)\n",
    "#     target_label[pad_idxs] = 0\n",
    "#     pred_labels[pad_idxs] = 0\n",
    "#     target_dist[pad_idxs] = MAX_DIST - 1\n",
    "#     pred_dists[pad_idxs] = MAX_DIST - 1\n",
    "\n",
    "#     images = images.astype(np.int)\n",
    "\n",
    "#     ndim = images.shape[0]\n",
    "#     if ndim > 1:\n",
    "#         images = montage(images, multichannel=True)\n",
    "#         target_dist = montage(target_dist)\n",
    "#         target_label = montage(target_label)\n",
    "#         pred_labels = montage(pred_labels)\n",
    "#         pred_dists = montage(pred_dists)\n",
    "#     else:\n",
    "#         images = images[0]\n",
    "#         target_dist = target_dist[0]\n",
    "#         target_label = target_label[0]\n",
    "#         pred_labels = pred_labels[0]\n",
    "#         pred_dists = pred_dists[0]\n",
    "\n",
    "#     N = 5\n",
    "#     plt.figure(figsize=(20, 10))\n",
    "#     plt.subplot(1, N, 1)\n",
    "#     plt.imshow(images)\n",
    "#     plt.title('Input images')\n",
    "\n",
    "#     plt.subplot(1, N, 2)\n",
    "#     plt.imshow(target_label)\n",
    "#     plt.title('Target labels')\n",
    "\n",
    "#     plt.subplot(1, N, 3)\n",
    "#     plt.imshow(pred_labels)\n",
    "#     plt.title('Predicted labels')\n",
    "\n",
    "#     plt.subplot(1, N, 4)\n",
    "#     plt.imshow(target_dist)\n",
    "#     plt.title('Target dists')\n",
    "\n",
    "#     plt.subplot(1, N, 5)\n",
    "#     plt.imshow(pred_dists)\n",
    "#     plt.title('Predicted dists')\n",
    "\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logging to zcode/tb-logs/vanilla-gan-20250429-153005\n"
     ]
    }
   ],
   "source": [
    "version = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "log_dir = f\"zcode/tb-logs/vanilla-gan-{version}\"\n",
    "logger_d = SummaryWriter(logdir=log_dir)\n",
    "print(f\"logging to {log_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6007 (pid 73673), started 0:00:02 ago. (Use '!kill 73673' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-176f04c9ff9e9565\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-176f04c9ff9e9565\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir \"{log_dir}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train / val functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title func: validate\n",
    "def validate(dataloader, n_batches, model, loss_func, log_func=None):\n",
    "  model.train(False)\n",
    "  model.eval()\n",
    "  device = next(model.parameters()).device\n",
    "\n",
    "  loss = 0\n",
    "  n_correct, n_total = 0, 0\n",
    "  for ix, batch_val in enumerate(dataloader):\n",
    "    if ix >= n_batches: break\n",
    "    images_val, labels_val = batch_val\n",
    "\n",
    "    # Get the loss\n",
    "    log_probs, _ = model(images_val.to(device))\n",
    "    loss += loss_func(log_probs, labels_val.to(device)).data.cpu().numpy()\n",
    "\n",
    "    # Get the acc\n",
    "    preds = np.argmax(log_probs.data.cpu().numpy(), axis=-1)\n",
    "    n_correct += np.sum(preds == labels_val)\n",
    "    n_total += labels_val.shape[0]\n",
    "\n",
    "    # if ix == 0:\n",
    "    #   image_montage = montage(images_val.squeeze().data.cpu().numpy())\n",
    "    #   plt.figure(figsize=(5, 5))\n",
    "    #   plt.subplot(1, 1, 1)\n",
    "    #   plt.imshow(image_montage)\n",
    "    #   plt.title(f\"Labels: {labels_val.data.cpu().numpy()}\\nPreds: {preds}\")\n",
    "    #   plt.show()\n",
    "\n",
    "  model.train(True)\n",
    "  loss /= n_batches\n",
    "  if log_func:\n",
    "    log_func(tag=\"disc.loss.val\", scalar_value=loss)\n",
    "    log_func(tag=\"disc.acc.val\", scalar_value=n_correct/n_total)\n",
    "  return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title func: train\n",
    "import math\n",
    "\n",
    "\n",
    "def train(dataloader, n_epochs, model, loss_func, optimizer,\n",
    "          logger, callback_frequency=100, callbacks=None,\n",
    "          es_smoothing=0.6, es_threshold=1e-8\n",
    "          ) -> None:\n",
    "  # Max steps to run for (in case of fractional n_epochs)\n",
    "  max_steps = len(dataloader)\n",
    "  if n_epochs < 1:\n",
    "    max_steps = math.ceil(n_epochs * max_steps)\n",
    "    n_epochs = 1\n",
    "\n",
    "  if callbacks is None:\n",
    "    callbacks = []\n",
    "\n",
    "  device = next(model.parameters()).device\n",
    "\n",
    "  # Running loss - for early stopping\n",
    "  average_loss = 0\n",
    "\n",
    "  for epoch in range(n_epochs):\n",
    "    for ix, batch_train in enumerate(dataloader):\n",
    "      step = ix + (epoch * len(dataloader))\n",
    "      if ix >= max_steps:\n",
    "        break\n",
    "    \n",
    "      # Get a train batch\n",
    "      images_train, labels_train = batch_train\n",
    "      \n",
    "      # Get preds\n",
    "      pred_log_probs_train, pred_probs_train = model(images_train.to(device))\n",
    "      \n",
    "      # calculate loss\n",
    "      optimizer.zero_grad()\n",
    "      loss_d_train = loss_func(pred_log_probs_train, labels_train.to(device))\n",
    "      \n",
    "      # backward\n",
    "      loss_d_train.backward()\n",
    "      optimizer.step()\n",
    "    \n",
    "      loss_val = loss_d_train.data.cpu().numpy()\n",
    "      # tensorboard logging\n",
    "      log_func = functools.partial(logger.add_scalar, global_step=step)\n",
    "      log_func(tag=\"disc.loss.train\", scalar_value=loss_val)\n",
    "\n",
    "      # early stopping\n",
    "      if np.abs(loss_val - average_loss) < es_threshold:\n",
    "        print(f\"Stopped early at iteration {step} with {loss_val}, average: {average_loss}\")\n",
    "        return\n",
    "      average_loss = average_loss * es_smoothing + loss_val * (1 - es_smoothing)\n",
    "\n",
    "      # Call the callbacks!\n",
    "      if ix % callback_frequency == 0:\n",
    "        _ = [f(model=model, log_func=log_func, loss_func=loss_func) for f in callbacks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title class: Deconv, Generator\n",
    "class Deconv(torch.nn.Module):\n",
    "    def __init__(self, n_c_in, n_c_out):\n",
    "        super().__init__()\n",
    "        self.b1 = torch.nn.Sequential(\n",
    "            torch.nn.ConvTranspose2d(n_c_in, n_c_out, kernel_size=2, stride=2, padding=0),\n",
    "            torch.nn.BatchNorm2d(n_c_out),\n",
    "            torch.nn.LeakyReLU(0.2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.b1(x)\n",
    "\n",
    "class Generator(torch.nn.Module):\n",
    "    def __init__(self, p_dropout=0):\n",
    "        super().__init__()\n",
    "        # deconv are the set of layers that enlarge the encoded image to double size\n",
    "        self.deconv1 = Deconv(64, 32)\n",
    "        self.deconv2 = Deconv(32, 32)\n",
    "        self.deconv3 = Deconv(32, 16)\n",
    "        # decoder uses deconvolution to creates the segmented image from encoded images using U-net structure\n",
    "        self.decoder1 = Encoder(32, 32, p_dropout)\n",
    "        self.decoder2 = Encoder(32, 32, p_dropout)\n",
    "        self.decoder3 = Encoder(16, 16, p_dropout)\n",
    "        self.word_pred = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(16, 1, kernel_size=(1, 1), stride=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        deconved1 = self.deconv1(inputs)\n",
    "        decoded1 = self.decoder1(deconved1)\n",
    "        deconved2 = self.deconv2(decoded1)\n",
    "        decoded2 = self.decoder2(deconved2)\n",
    "        deconved3 = self.deconv3(decoded2)\n",
    "        decoded3 = self.decoder3(deconved3)\n",
    "        activations = self.word_pred(decoded3)\n",
    "        return torch.tanh(activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Generator configs\n",
    "batch_size_g =   32#@param\n",
    "n_epochs_g =   1#@param\n",
    "\n",
    "n_epochs_d =   1#@param\n",
    "batch_size_d = 32  #@param\n",
    "n_cycles = 700  #@param\n",
    "\n",
    "half_bsz = batch_size_d // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title class: RealGenDataset\n",
    "class RealGenDataset(torch.utils.data.Dataset):\n",
    "  \"\"\"\n",
    "  Discriminator Labels:\n",
    "    - Generated: 1\n",
    "    - Real: 0\n",
    "  \n",
    "  If using with \"only_generated\", I flip the labels:\n",
    "    - Generated: 0\n",
    "  \n",
    "  This is simply done for easy code reuse while training the generator since\n",
    "  we want the discriminator to think that the generated images are real\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, dataset_real, model_gen, only_generated=False):\n",
    "    self.dataset = dataset_real\n",
    "    self.generator = model_gen\n",
    "    self.device = next(model_gen.parameters()).device\n",
    "    self.only_generated = only_generated\n",
    "  \n",
    "  def __len__(self):\n",
    "    return len(self.dataset)\n",
    "  \n",
    "  def __getitem__(self, ix, rng=None):\n",
    "    image_real, _ = self.dataset[ix]\n",
    "\n",
    "    if rng is not None:\n",
    "      np.random.seed(rng)\n",
    "    \n",
    "    z = torch.from_numpy(np.random.randn(1, 64, 4, 4).astype(np.float32))\n",
    "    # Note: still attached to the graph\n",
    "    image_gen = self.generator(z.to(self.device)).cpu() \n",
    "\n",
    "    if self.only_generated:\n",
    "      return image_gen, torch.from_numpy(np.array([0]).astype(np.long))\n",
    "\n",
    "    images = torch.cat([image_real.view(1, *image_real.shape), image_gen], dim=0)\n",
    "    labels = torch.from_numpy(np.array([0, 1]).astype(np.long))\n",
    "    return (images, labels)\n",
    "\n",
    "def collate_batches(batches):\n",
    "  images = torch.cat([b[0] for b in batches], dim=0)\n",
    "  labels = torch.cat([b[1] for b in batches], dim=0)\n",
    "  return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_g = Generator().to(device)\n",
    "model_d = CNNDiscriminator(n_channels=1, n_classes=2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 32, 32]) torch.Size([32]) tensor([0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
      "        0, 1, 0, 1, 0, 1, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "#@title get dataset_train_d dataloader_train_d dataset_test_d dataloader_test_d\n",
    "\n",
    "dataset_train_d = RealGenDataset(dataset_train, model_g)\n",
    "dataloader_train_d = DataLoader(\n",
    "    dataset_train_d,\n",
    "    batch_size=half_bsz,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_batches\n",
    "    )\n",
    "\n",
    "dataset_test_d = RealGenDataset(dataset_test, model_g)\n",
    "dataloader_test_d = DataLoader(\n",
    "    dataset_test_d,\n",
    "    batch_size=half_bsz,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_batches\n",
    "    )\n",
    "\n",
    "# Check if it makes sense\n",
    "images, labels = next(iter(dataloader_train_d))\n",
    "print(images.shape, labels.shape, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 32, 32]) torch.Size([32]) tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "#@title get dataset_train_g dataloader_train_g dataset_test_g dataloader_test_g\n",
    "\n",
    "dataset_train_g = RealGenDataset(dataset_train, model_g, only_generated=True)\n",
    "dataloader_train_g = DataLoader(\n",
    "    dataset_train_g,\n",
    "    batch_size=batch_size_g,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_batches\n",
    "    )\n",
    "\n",
    "dataset_test_g = RealGenDataset(dataset_test, model_g, only_generated=True)\n",
    "dataloader_test_g = DataLoader(\n",
    "    dataset_test_g,\n",
    "    batch_size=batch_size_g,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_batches\n",
    "    )\n",
    "\n",
    "# Check if it makes sense\n",
    "images, labels = next(iter(dataloader_train_g))\n",
    "print(images.shape, labels.shape, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title loss functions and optimizers\n",
    "loss_d = torch.nn.NLLLoss()\n",
    "loss_g = torch.nn.NLLLoss()\n",
    "optimizer_d = torch.optim.Adam(model_d.parameters())\n",
    "optimizer_g = torch.optim.Adam(model_g.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_batch(batch, model, optimizer, loss_func):\n",
    "  # Get a train batch\n",
    "  images_train, labels_train = batch\n",
    "  \n",
    "  # Get preds\n",
    "  pred_log_probs_train, pred_probs_train = model(images_train.to(device))\n",
    "  \n",
    "  # calculate loss\n",
    "  optimizer.zero_grad()\n",
    "  loss_d_train = loss_func(pred_log_probs_train, labels_train.to(device))\n",
    "  \n",
    "  # backward\n",
    "  loss_d_train.backward()\n",
    "  optimizer.step()\n",
    "\n",
    "  return loss_d_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_foo():\n",
    "  print(f\"G: {next(model_g.parameters()).mean(), next(model_g.parameters()).std()}\")\n",
    "  print(f\"D: {next(model_d.parameters()).mean(), next(model_d.parameters()).std()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m model_d\u001b[38;5;241m.\u001b[39mtrain(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     25\u001b[0m model_g\u001b[38;5;241m.\u001b[39mtrain(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 26\u001b[0m loss_train_g \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader_train_g\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer_g\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_g\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m logger_d\u001b[38;5;241m.\u001b[39madd_scalar(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgen.loss.train\u001b[39m\u001b[38;5;124m\"\u001b[39m, loss_train_g\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy(), step)\n",
      "Cell \u001b[0;32mIn[27], line 13\u001b[0m, in \u001b[0;36mtrain_one_batch\u001b[0;34m(batch, model, optimizer, loss_func)\u001b[0m\n\u001b[1;32m     10\u001b[0m loss_d_train \u001b[38;5;241m=\u001b[39m loss_func(pred_log_probs_train, labels_train\u001b[38;5;241m.\u001b[39mto(device))\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# backward\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[43mloss_d_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss_d_train\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/toylib2/lib/python3.9/site-packages/torch/_tensor.py:648\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    639\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    640\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    641\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    646\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    647\u001b[0m     )\n\u001b[0;32m--> 648\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/toylib2/lib/python3.9/site-packages/torch/autograd/__init__.py:353\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    348\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    350\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 353\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/toylib2/lib/python3.9/site-packages/torch/autograd/graph.py:824\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    822\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    823\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 824\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    828\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#@title train gan\n",
    "import time\n",
    "\n",
    "val_func_d = functools.partial(validate, dataloader=dataloader_test_d, n_batches=5)\n",
    "val_func_g = functools.partial(validate, dataloader=dataloader_test_g, n_batches=5)\n",
    "\n",
    "step =   0   ##@param\n",
    "start_time = time.time()\n",
    "while True:\n",
    "  step += 1\n",
    "\n",
    "  # Train the discrimator on one batch\n",
    "  model_d.train(True)\n",
    "  model_g.train(False)\n",
    "  loss_train_d = train_one_batch(\n",
    "      batch=next(iter(dataloader_train_d)),\n",
    "      model=model_d,\n",
    "      optimizer=optimizer_d,\n",
    "      loss_func=loss_d\n",
    "  )\n",
    "  logger_d.add_scalar(\"dis.loss.train\", loss_train_d.data.cpu().numpy(), step)\n",
    "\n",
    "  # Train the generator on one batch\n",
    "  model_d.train(False)\n",
    "  model_g.train(True)\n",
    "  loss_train_g = train_one_batch(\n",
    "      batch=next(iter(dataloader_train_g)),\n",
    "      model=model_d,\n",
    "      optimizer=optimizer_g,\n",
    "      loss_func=loss_g\n",
    "  )\n",
    "  logger_d.add_scalar(\"gen.loss.train\", loss_train_g.data.cpu().numpy(), step)\n",
    "\n",
    "  # # Validation \n",
    "  # if step % 200 == 0:\n",
    "  #   loss_val_g = val_func_g(model=model_d, loss_func=loss_g)\n",
    "  #   loss_val_d = val_func_d(model=model_d, loss_func=loss_d)\n",
    "  #   logger_d.add_scalar(\"gen.loss.val\", loss_val_g, step)\n",
    "  #   logger_d.add_scalar(\"dis.loss.val\", loss_val_d, step)\n",
    "  \n",
    "  # # Save\n",
    "  # if step % 2000 == 0:\n",
    "  #   torch.save(model_d, log_dir + f\"model_d_{step}.pt\")\n",
    "  #   torch.save(model_g, log_dir + f\"model_g_{step}.pt\")\n",
    "  #   print(f\"seconds elapsed since last checkpoint: {time.time() - start_time}\")\n",
    "  #   start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seconds elapsed since last checkpoint: 7325.823907852173\n"
     ]
    }
   ],
   "source": [
    "torch.save(model_d, log_dir + f\"model_d_{step}.pt\")\n",
    "torch.save(model_g, log_dir + f\"model_g_{step}.pt\")\n",
    "print(f\"seconds elapsed since last checkpoint: {time.time() - start_time}\")\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44769"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
