{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b88c8ea6-8023-45ae-a075-2b70d2478082",
   "metadata": {},
   "source": [
    "# \n",
    "From \n",
    "https://jax.readthedocs.io/en/latest/notebooks/neural_network_with_tfds_data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80f170d5-43f7-428d-8771-88be822e27b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "from jax import grad, jit, vmap\n",
    "from jax import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bac08049-1b17-493e-909a-2ff643c0d4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_layer_params(m, n, key, scale=1e-2):\n",
    "    w_key, b_key = random.split(key)\n",
    "    return scale * random.normal(w_key, (n, m)), scale * random.normal(b_key, (n,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3a0a74a-4758-450f-8d76-ec0222f9e654",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_network_params(sizes, key):\n",
    "    keys = random.split(key, len(sizes))\n",
    "    return [random_layer_params(m, n, k) for m, n, k in zip(sizes[:-1], sizes[1:], keys)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92cfaf37-eef9-4cb5-8283-dfceb083e979",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1701557099.478758   18039 tfrt_cpu_pjrt_client.cc:349] TfrtCpuClient created.\n",
      "No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "n_targets = 10\n",
    "step_size = 0.01\n",
    "num_epochs = 10\n",
    "batch_size = 128\n",
    "\n",
    "layer_sizes = [784, 512, 512, n_targets]\n",
    "params = init_network_params(layer_sizes, random.PRNGKey(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe54ca5b-a3b0-457f-8f93-0ac979f47b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.scipy.special import logsumexp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8a25ae1-2031-4f53-b78a-dbae806111ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return jnp.maximum(0, x)\n",
    "\n",
    "def predict(params, image):\n",
    "    activations = image\n",
    "    for w, b in params[:-1]:\n",
    "        outputs = jnp.dot(w, activations) + b\n",
    "        activations = relu(outputs)\n",
    "    final_w, final_b = params[-1]\n",
    "    logits = jnp.dot(final_w, activations) + final_b\n",
    "    return logits - logsumexp(logits)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79349525-066f-405f-bbc9-763cb6ac41dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "dot_general requires contracting dimensions to have the same shape, got (784,) and (10,).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m random_image \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mnormal(random\u001b[38;5;241m.\u001b[39mPRNGKey(\u001b[38;5;241m1\u001b[39m), (\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m28\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m28\u001b[39m,))\n\u001b[0;32m----> 2\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_image\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m preds\u001b[38;5;241m.\u001b[39mshape\n",
      "Cell \u001b[0;32mIn[6], line 7\u001b[0m, in \u001b[0;36mpredict\u001b[0;34m(params, image)\u001b[0m\n\u001b[1;32m      5\u001b[0m activations \u001b[38;5;241m=\u001b[39m image\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m w, b \u001b[38;5;129;01min\u001b[39;00m params[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m----> 7\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mjnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivations\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m b\n\u001b[1;32m      8\u001b[0m     activations \u001b[38;5;241m=\u001b[39m relu(outputs)\n\u001b[1;32m      9\u001b[0m final_w, final_b \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "    \u001b[0;31m[... skipping hidden 12 frame]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/jax-py310/lib/python3.10/site-packages/jax/_src/numpy/lax_numpy.py:3101\u001b[0m, in \u001b[0;36mdot\u001b[0;34m(a, b, precision, preferred_element_type)\u001b[0m\n\u001b[1;32m   3099\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3100\u001b[0m     contract_dims \u001b[38;5;241m=\u001b[39m ((a_ndim \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m,), (b_ndim \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m2\u001b[39m,))\n\u001b[0;32m-> 3101\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mlax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot_general\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdimension_numbers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcontract_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_dims\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3102\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mprecision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprecision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreferred_element_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreferred_element_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m lax_internal\u001b[38;5;241m.\u001b[39m_convert_element_type(result, preferred_element_type, output_weak_type)\n",
      "    \u001b[0;31m[... skipping hidden 7 frame]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/jax-py310/lib/python3.10/site-packages/jax/_src/lax/lax.py:2557\u001b[0m, in \u001b[0;36m_dot_general_shape_rule\u001b[0;34m(lhs, rhs, dimension_numbers, precision, preferred_element_type)\u001b[0m\n\u001b[1;32m   2554\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m core\u001b[38;5;241m.\u001b[39mdefinitely_equal_shape(lhs_contracting_shape, rhs_contracting_shape):\n\u001b[1;32m   2555\u001b[0m   msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdot_general requires contracting dimensions to have the same \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2556\u001b[0m          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2557\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg\u001b[38;5;241m.\u001b[39mformat(lhs_contracting_shape, rhs_contracting_shape))\n\u001b[1;32m   2559\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _dot_general_shape_computation(lhs\u001b[38;5;241m.\u001b[39mshape, rhs\u001b[38;5;241m.\u001b[39mshape, dimension_numbers)\n",
      "\u001b[0;31mTypeError\u001b[0m: dot_general requires contracting dimensions to have the same shape, got (784,) and (10,)."
     ]
    }
   ],
   "source": [
    "random_image = random.normal(random.PRNGKey(1), (10, 28*28,))\n",
    "preds = predict(params, random_image)\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ef876ba-11eb-4965-9687-7498ac5211f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batched_predict = vmap(predict, in_axes=(None, 0))\n",
    "batched_predict(params, random.normal(random.PRNGKey(1), (10, 28*28))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6ba2cfb-a9a1-4604-b4c3-1f818e057e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(x, k, dtype=jnp.float32):\n",
    "    return jnp.array(x[:, None] == jnp.arange(k), dtype)\n",
    "\n",
    "def accuracy(params, images, targets):\n",
    "    target_class = jnp.argmax(targets, axis=1)\n",
    "    predicted_class = jnp.argmax(batched_predict(params, images), axis=1)\n",
    "    return jnp.mean(predicted_class == target_class)\n",
    "\n",
    "def loss(params, images, targets):\n",
    "    preds = batched_predict(params, images)\n",
    "    return -jnp.mean(preds * targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0a886df-f379-4c71-8460-805f92dc18ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def update(params, x, y):\n",
    "    grads = grad(loss)(params, x, y)\n",
    "    return [\n",
    "        (w - step_size * dw, b - step_size * db)\n",
    "        for (w, b), (dw, db) in zip(params, grads)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7514f0cf-2b56-4780-8de6-d7b3c9934f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kcm/miniconda3/envs/jax-py310/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset mnist (11.06 MiB) to /tmp/tfds/mnist/1.0.0...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dl Completed...: 0 url [00:00, ? url/s]\n",
      "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                                                          | 0/1 [00:00<?, ? url/s]\n",
      "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                                                          | 0/2 [00:00<?, ? url/s]\n",
      "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                                                          | 0/3 [00:00<?, ? url/s]\n",
      "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                                                          | 0/4 [00:00<?, ? url/s]\n",
      "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:00, ? file/s]\u001b[A\u001b[A/home/kcm/miniconda3/envs/jax-py310/lib/python3.10/site-packages/urllib3/connectionpool.py:1061: InsecureRequestWarning: Unverified HTTPS request is being made to host 'storage.googleapis.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/home/kcm/miniconda3/envs/jax-py310/lib/python3.10/site-packages/urllib3/connectionpool.py:1061: InsecureRequestWarning: Unverified HTTPS request is being made to host 'storage.googleapis.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/home/kcm/miniconda3/envs/jax-py310/lib/python3.10/site-packages/urllib3/connectionpool.py:1061: InsecureRequestWarning: Unverified HTTPS request is being made to host 'storage.googleapis.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/home/kcm/miniconda3/envs/jax-py310/lib/python3.10/site-packages/urllib3/connectionpool.py:1061: InsecureRequestWarning: Unverified HTTPS request is being made to host 'storage.googleapis.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "Dl Completed...:   0%|                                                                          | 0/4 [00:00<?, ? url/s]\n",
      "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                                                          | 0/4 [00:00<?, ? url/s]\n",
      "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                                                          | 0/4 [00:00<?, ? url/s]\n",
      "Dl Size...:   0%|                                                                               | 0/9 [00:00<?, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  25%|████████████████▌                                                 | 1/4 [00:00<00:00,  5.19 url/s]\n",
      "Dl Size...:   0%|                                                                               | 0/9 [00:00<?, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  25%|████████████████▌                                                 | 1/4 [00:00<00:00,  5.19 url/s]\n",
      "Dl Size...:   0%|                                                                              | 0/10 [00:00<?, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  50%|█████████████████████████████████                                 | 2/4 [00:00<00:00,  5.19 url/s]\n",
      "Dl Size...:   0%|                                                                              | 0/10 [00:00<?, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  50%|█████████████████████████████████                                 | 2/4 [00:00<00:00,  5.19 url/s]\n",
      "Dl Size...:   0%|                                                                              | 0/10 [00:00<?, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  50%|█████████████████████████████████                                 | 2/4 [00:00<00:00,  5.19 url/s]\u001b[A\u001b[A\n",
      "Dl Size...:   0%|                                                                              | 0/10 [00:00<?, ? MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...:   0%|                                                                 | 0/2 [00:00<?, ? file/s]\u001b[A\u001b[A\n",
      "\n",
      "Dl Completed...:  50%|█████████████████████████████████                                 | 2/4 [00:00<00:00,  5.19 url/s]\u001b[A\u001b[A\n",
      "Dl Size...:   0%|                                                                              | 0/10 [00:00<?, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  50%|█████████████████████████████████                                 | 2/4 [00:00<00:00,  5.19 url/s]\u001b[A\u001b[A\n",
      "Dl Size...:   0%|                                                                              | 0/10 [00:00<?, ? MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 100%|█████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  4.15 file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  50%|█████████████████████████████████                                 | 2/4 [00:00<00:00,  5.19 url/s]\u001b[A\n",
      "Dl Size...:  10%|███████                                                               | 1/10 [00:00<00:03,  2.91 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 100%|█████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  4.15 file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  50%|█████████████████████████████████                                 | 2/4 [00:00<00:00,  5.19 url/s]\u001b[A\n",
      "Dl Size...:  20%|██████████████                                                        | 2/10 [00:00<00:01,  4.32 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 100%|█████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  4.15 file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  50%|█████████████████████████████████                                 | 2/4 [00:00<00:00,  5.19 url/s]\u001b[A\n",
      "Dl Size...:  30%|█████████████████████                                                 | 3/10 [00:00<00:01,  5.38 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  50%|█████████████████████████████████                                 | 2/4 [00:00<00:00,  5.19 url/s]\u001b[A\u001b[A\n",
      "Dl Size...:  40%|████████████████████████████                                          | 4/10 [00:00<00:01,  5.38 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 100%|█████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  4.15 file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  50%|█████████████████████████████████                                 | 2/4 [00:00<00:00,  5.19 url/s]\u001b[A\n",
      "Dl Size...:  50%|███████████████████████████████████                                   | 5/10 [00:00<00:00,  9.13 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  50%|█████████████████████████████████                                 | 2/4 [00:00<00:00,  5.19 url/s]\u001b[A\u001b[A\n",
      "Dl Size...:  60%|██████████████████████████████████████████                            | 6/10 [00:00<00:00,  9.13 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  50%|█████████████████████████████████                                 | 2/4 [00:00<00:00,  5.19 url/s]\u001b[A\u001b[A\n",
      "Dl Size...:  70%|█████████████████████████████████████████████████                     | 7/10 [00:00<00:00,  9.13 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 100%|█████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  4.15 file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  50%|█████████████████████████████████                                 | 2/4 [00:00<00:00,  5.19 url/s]\u001b[A\n",
      "Dl Size...:  80%|████████████████████████████████████████████████████████              | 8/10 [00:00<00:00, 12.02 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  75%|█████████████████████████████████████████████████▌                | 3/4 [00:00<00:00,  3.03 url/s]\u001b[A\u001b[A\n",
      "Dl Size...:  80%|████████████████████████████████████████████████████████              | 8/10 [00:00<00:00, 12.02 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  75%|█████████████████████████████████████████████████▌                | 3/4 [00:00<00:00,  3.03 url/s]\u001b[A\u001b[A\n",
      "Dl Size...:  80%|████████████████████████████████████████████████████████              | 8/10 [00:00<00:00, 12.02 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  75%|█████████████████████████████████████████████████▌                | 3/4 [00:00<00:00,  3.03 url/s]\u001b[A\u001b[A\n",
      "Dl Size...:  90%|███████████████████████████████████████████████████████████████       | 9/10 [00:00<00:00, 12.02 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...:  67%|██████████████████████████████████████                   | 2/3 [00:00<00:00,  4.15 file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  75%|█████████████████████████████████████████████████▌                | 3/4 [00:01<00:00,  3.03 url/s]\u001b[A\n",
      "Dl Size...: 100%|█████████████████████████████████████████████████████████████████████| 10/10 [00:01<00:00, 13.05 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...:  67%|██████████████████████████████████████                   | 2/3 [00:01<00:00,  4.15 file/s]\u001b[A\u001b[A\n",
      "\n",
      "Dl Completed...:  75%|█████████████████████████████████████████████████▌                | 3/4 [00:01<00:00,  3.03 url/s]\u001b[A\u001b[A\n",
      "Dl Size...: 100%|█████████████████████████████████████████████████████████████████████| 10/10 [00:01<00:00, 13.05 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...: 100%|██████████████████████████████████████████████████████████████████| 4/4 [00:01<00:00,  3.84 url/s]\u001b[A\u001b[A\n",
      "Dl Size...: 100%|█████████████████████████████████████████████████████████████████████| 10/10 [00:01<00:00, 13.05 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...: 100%|██████████████████████████████████████████████████████████████████| 4/4 [00:01<00:00,  3.84 url/s]\u001b[A\u001b[A\n",
      "Dl Size...: 100%|█████████████████████████████████████████████████████████████████████| 10/10 [00:01<00:00, 13.05 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...:  75%|██████████████████████████████████████████▊              | 3/4 [00:01<00:00,  2.74 file/s]\u001b[A\u001b[A\n",
      "\n",
      "Dl Completed...: 100%|██████████████████████████████████████████████████████████████████| 4/4 [00:01<00:00,  3.84 url/s]\u001b[A\u001b[A\n",
      "Dl Size...: 100%|█████████████████████████████████████████████████████████████████████| 10/10 [00:01<00:00, 13.05 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 100%|█████████████████████████████████████████████████████████| 4/4 [00:01<00:00,  3.04 file/s]\u001b[A\u001b[A\n",
      "Dl Size...: 100%|█████████████████████████████████████████████████████████████████████| 10/10 [00:01<00:00,  7.57 MiB/s]\n",
      "Dl Completed...: 100%|██████████████████████████████████████████████████████████████████| 4/4 [00:01<00:00,  3.02 url/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Shuffling...:   0%|                                                                          | 0/10 [00:00<?, ? shard/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kcm/miniconda3/envs/jax-py310/lib/python3.10/site-packages/tensorflow_datasets/core/file_format_adapter.py:209: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kcm/miniconda3/envs/jax-py310/lib/python3.10/site-packages/tensorflow_datasets/core/file_format_adapter.py:209: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n",
      "\n",
      "Reading...: 0 examples [00:00, ? examples/s]\u001b[A\n",
      "                                            \u001b[A\n",
      "Writing...:   0%|                                                                       | 0/6000 [00:00<?, ? examples/s]\u001b[A\n",
      "                                                                                                                        \u001b[A\n",
      "Reading...: 0 examples [00:00, ? examples/s]\u001b[A\n",
      "                                            \u001b[A\n",
      "Writing...:   0%|                                                                       | 0/6000 [00:00<?, ? examples/s]\u001b[A\n",
      "                                                                                                                        \u001b[A\n",
      "Reading...: 0 examples [00:00, ? examples/s]\u001b[A\n",
      "                                            \u001b[A\n",
      "Writing...:   0%|                                                                       | 0/6000 [00:00<?, ? examples/s]\u001b[A\n",
      "                                                                                                                        \u001b[A\n",
      "Reading...: 0 examples [00:00, ? examples/s]\u001b[A\n",
      "                                            \u001b[A\n",
      "Writing...:   0%|                                                                       | 0/6000 [00:00<?, ? examples/s]\u001b[A\n",
      "Shuffling...:  40%|██████████████████████████▍                                       | 4/10 [00:00<00:00, 33.23 shard/s]\u001b[A\n",
      "Reading...: 0 examples [00:00, ? examples/s]\u001b[A\n",
      "                                            \u001b[A\n",
      "Writing...:   0%|                                                                       | 0/6000 [00:00<?, ? examples/s]\u001b[A\n",
      "                                                                                                                        \u001b[A\n",
      "Reading...: 0 examples [00:00, ? examples/s]\u001b[A\n",
      "                                            \u001b[A\n",
      "Writing...:   0%|                                                                       | 0/6000 [00:00<?, ? examples/s]\u001b[A\n",
      "                                                                                                                        \u001b[A\n",
      "Reading...: 0 examples [00:00, ? examples/s]\u001b[A\n",
      "                                            \u001b[A\n",
      "Writing...:   0%|                                                                       | 0/6000 [00:00<?, ? examples/s]\u001b[A\n",
      "                                                                                                                        \u001b[A\n",
      "Reading...: 0 examples [00:00, ? examples/s]\u001b[A\n",
      "                                            \u001b[A\n",
      "Writing...:   0%|                                                                       | 0/6000 [00:00<?, ? examples/s]\u001b[A\n",
      "                                                                                                                        \u001b[A\n",
      "Reading...: 0 examples [00:00, ? examples/s]\u001b[A\n",
      "                                            \u001b[A\n",
      "Writing...:   0%|                                                                       | 0/6000 [00:00<?, ? examples/s]\u001b[A\n",
      "Shuffling...:  90%|███████████████████████████████████████████████████████████▍      | 9/10 [00:00<00:00, 39.80 shard/s]\u001b[A\n",
      "Reading...: 0 examples [00:00, ? examples/s]\u001b[A\n",
      "                                            \u001b[A\n",
      "Writing...:   0%|                                                                       | 0/6000 [00:00<?, ? examples/s]\u001b[A\n",
      "Shuffling...:   0%|                                                                           | 0/1 [00:00<?, ? shard/s]\u001b[A\n",
      "Reading...: 0 examples [00:00, ? examples/s]\u001b[A\n",
      "                                            \u001b[A\n",
      "Writing...:   0%|                                                                      | 0/10000 [00:00<?, ? examples/s]\u001b[A\n",
      "                                                                                                                        \u001b[A\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset mnist downloaded and prepared to /tmp/tfds/mnist/1.0.0. Subsequent calls will reuse this data.\u001b[0m\n",
      "WARNING:tensorflow:From /home/kcm/miniconda3/envs/jax-py310/lib/python3.10/site-packages/tensorflow_datasets/core/dataset_builder.py:513: get_single_element (from tensorflow.python.data.experimental.ops.get_single_element) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.get_single_element()`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kcm/miniconda3/envs/jax-py310/lib/python3.10/site-packages/tensorflow_datasets/core/dataset_builder.py:513: get_single_element (from tensorflow.python.data.experimental.ops.get_single_element) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.get_single_element()`.\n",
      "WARNING:absl:Warning: Setting shuffle_files=True because split=TRAIN and shuffle_files=None. This behavior will be deprecated on 2019-08-06, at which point shuffle_files=False will be the default for all splits.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# Ensure TF does not see GPU and grab all GPU memory.\n",
    "tf.config.set_visible_devices([], device_type='GPU')\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "data_dir = '/tmp/tfds'\n",
    "\n",
    "# Fetch full datasets for evaluation\n",
    "# tfds.load returns tf.Tensors (or tf.data.Datasets if batch_size != -1)\n",
    "# You can convert them to NumPy arrays (or iterables of NumPy arrays) with tfds.dataset_as_numpy\n",
    "mnist_data, info = tfds.load(name=\"mnist\", batch_size=-1, data_dir=data_dir, with_info=True)\n",
    "mnist_data = tfds.as_numpy(mnist_data)\n",
    "train_data, test_data = mnist_data['train'], mnist_data['test']\n",
    "num_labels = info.features['label'].num_classes\n",
    "h, w, c = info.features['image'].shape\n",
    "num_pixels = h * w * c\n",
    "\n",
    "# Full train set\n",
    "train_images, train_labels = train_data['image'], train_data['label']\n",
    "train_images = jnp.reshape(train_images, (len(train_images), num_pixels))\n",
    "train_labels = one_hot(train_labels, num_labels)\n",
    "\n",
    "# Full test set\n",
    "test_images, test_labels = test_data['image'], test_data['label']\n",
    "test_images = jnp.reshape(test_images, (len(test_images), num_pixels))\n",
    "test_labels = one_hot(test_labels, num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad200bf4-44e5-430d-8943-d976ee485ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (60000, 784) (60000, 10)\n",
      "Test: (10000, 784) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print('Train:', train_images.shape, train_labels.shape)\n",
    "print('Test:', test_images.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6607151c-1fb2-4bdd-9bd5-c48e1856e353",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Warning: Setting shuffle_files=True because split=TRAIN and shuffle_files=None. This behavior will be deprecated on 2019-08-06, at which point shuffle_files=False will be the default for all splits.\n",
      "WARNING:absl:Warning: Setting shuffle_files=True because split=TRAIN and shuffle_files=None. This behavior will be deprecated on 2019-08-06, at which point shuffle_files=False will be the default for all splits.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 in 3.04 sec\n",
      "Training set accuracy 0.9192333221435547\n",
      "Test set accuracy 0.9192999601364136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Warning: Setting shuffle_files=True because split=TRAIN and shuffle_files=None. This behavior will be deprecated on 2019-08-06, at which point shuffle_files=False will be the default for all splits.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 in 2.83 sec\n",
      "Training set accuracy 0.9392333626747131\n",
      "Test set accuracy 0.9382999539375305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Warning: Setting shuffle_files=True because split=TRAIN and shuffle_files=None. This behavior will be deprecated on 2019-08-06, at which point shuffle_files=False will be the default for all splits.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 in 2.80 sec\n",
      "Training set accuracy 0.9499500393867493\n",
      "Test set accuracy 0.9484999775886536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Warning: Setting shuffle_files=True because split=TRAIN and shuffle_files=None. This behavior will be deprecated on 2019-08-06, at which point shuffle_files=False will be the default for all splits.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 in 3.26 sec\n",
      "Training set accuracy 0.9591000080108643\n",
      "Test set accuracy 0.9563999772071838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Warning: Setting shuffle_files=True because split=TRAIN and shuffle_files=None. This behavior will be deprecated on 2019-08-06, at which point shuffle_files=False will be the default for all splits.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 in 2.59 sec\n",
      "Training set accuracy 0.9643666744232178\n",
      "Test set accuracy 0.9608999490737915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Warning: Setting shuffle_files=True because split=TRAIN and shuffle_files=None. This behavior will be deprecated on 2019-08-06, at which point shuffle_files=False will be the default for all splits.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 in 2.93 sec\n",
      "Training set accuracy 0.9688000082969666\n",
      "Test set accuracy 0.9637999534606934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Warning: Setting shuffle_files=True because split=TRAIN and shuffle_files=None. This behavior will be deprecated on 2019-08-06, at which point shuffle_files=False will be the default for all splits.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 in 2.65 sec\n",
      "Training set accuracy 0.9726499915122986\n",
      "Test set accuracy 0.9664999842643738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Warning: Setting shuffle_files=True because split=TRAIN and shuffle_files=None. This behavior will be deprecated on 2019-08-06, at which point shuffle_files=False will be the default for all splits.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 in 3.05 sec\n",
      "Training set accuracy 0.9748333692550659\n",
      "Test set accuracy 0.9663999676704407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Warning: Setting shuffle_files=True because split=TRAIN and shuffle_files=None. This behavior will be deprecated on 2019-08-06, at which point shuffle_files=False will be the default for all splits.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 in 2.74 sec\n",
      "Training set accuracy 0.9777333736419678\n",
      "Test set accuracy 0.9695000052452087\n",
      "Epoch 9 in 3.08 sec\n",
      "Training set accuracy 0.9798499941825867\n",
      "Test set accuracy 0.97079998254776\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def get_train_batches():\n",
    "  # as_supervised=True gives us the (image, label) as a tuple instead of a dict\n",
    "  ds = tfds.load(name='mnist', split='train', as_supervised=True, data_dir=data_dir)\n",
    "  # You can build up an arbitrary tf.data input pipeline\n",
    "  ds = ds.batch(batch_size).prefetch(1)\n",
    "  # tfds.dataset_as_numpy converts the tf.data.Dataset into an iterable of NumPy arrays\n",
    "  return tfds.as_numpy(ds)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "  start_time = time.time()\n",
    "  for x, y in get_train_batches():\n",
    "    x = jnp.reshape(x, (len(x), num_pixels))\n",
    "    y = one_hot(y, num_labels)\n",
    "    params = update(params, x, y)\n",
    "  epoch_time = time.time() - start_time\n",
    "\n",
    "  train_acc = accuracy(params, train_images, train_labels)\n",
    "  test_acc = accuracy(params, test_images, test_labels)\n",
    "  print(\"Epoch {} in {:0.2f} sec\".format(epoch, epoch_time))\n",
    "  print(\"Training set accuracy {}\".format(train_acc))\n",
    "  print(\"Test set accuracy {}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db370e8e-9011-4ab3-9366-2c7863fa9de2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
