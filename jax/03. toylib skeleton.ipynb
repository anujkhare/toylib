{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the backbone of our toylib NN library!\n",
    "As we embark on the journey of creating more complex models, it would be good to have some reusable pieces.\n",
    "\n",
    "We create the foundation of our NN library, an abstract base class: `Module`, which all our other modules will inherit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC\n",
    "\n",
    "\n",
    "class Module(ABC):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our first Module is the `Linear` class: which simply creates a Feedforward layer.\n",
    "import math\n",
    "import jax\n",
    "\n",
    "from typing import Any, Optional\n",
    "from jaxtyping import Array, PRNGKeyArray\n",
    "\n",
    "\n",
    "class Linear(Module):\n",
    "    \"\"\"Defines a simple feedforward layer: which is a linear transformation.\"\"\"\n",
    "\n",
    "    weights: Array\n",
    "    bias: Optional[Array]\n",
    "\n",
    "    in_features: int\n",
    "    out_features: int\n",
    "    use_bias: bool\n",
    "\n",
    "    def __init__(self, in_features: int, out_features: int, use_bias: bool = True, *, key: PRNGKeyArray) -> None:\n",
    "        w_key, b_key = jax.random.split(key, 2)\n",
    "        lim = 1 / math.sqrt(in_features)\n",
    "        self.weights = jax.random.uniform(w_key, (out_features, in_features), minval=-lim, maxval=lim)\n",
    "        if use_bias:\n",
    "            self.bias = jax.random.uniform(b_key, (out_features,), minval=-lim, maxval=lim)\n",
    "\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.use_bias = use_bias\n",
    "\n",
    "    def __call__(self, x: Array) -> Array:\n",
    "        x = jax.numpy.dot(self.weights, x)\n",
    "        if self.use_bias:\n",
    "            x = x + self.bias\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `jaxtyping` library is used to define types in addition to the standard py library `typing`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.PRNGKey(seed=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1 = Linear(10, 2, key=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6799785  0.3947947  0.87870073 0.31470668 0.07135046 0.65858626\n",
      " 0.44972312 0.4361874  0.809513   0.40791905]\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "x = jax.random.uniform(key, (10,))\n",
    "print(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([-0.74184865, -0.12828125], dtype=float32)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer1(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et voila! We have a simple linear layer defined! In a real network, we would use the layer on a batch of examples of at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "dot_general requires contracting dimensions to have the same shape, got (10,) and (8,).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\code\\mlfromjax\\nn\\01. NN discriminative.ipynb Cell 10\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/c%3A/code/mlfromjax/nn/01.%20NN%20discriminative.ipynb#X42sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m x_batch \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mnormal(key, (\u001b[39m8\u001b[39m, \u001b[39m10\u001b[39m))  \u001b[39m# batch_size = 8\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/c%3A/code/mlfromjax/nn/01.%20NN%20discriminative.ipynb#X42sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m layer1(x_batch)\n",
      "\u001b[1;32mc:\\code\\mlfromjax\\nn\\01. NN discriminative.ipynb Cell 10\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/c%3A/code/mlfromjax/nn/01.%20NN%20discriminative.ipynb#X42sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, x: Array) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Array:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/c%3A/code/mlfromjax/nn/01.%20NN%20discriminative.ipynb#X42sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     x \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39;49mnumpy\u001b[39m.\u001b[39;49mdot(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweights, x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/c%3A/code/mlfromjax/nn/01.%20NN%20discriminative.ipynb#X42sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_bias:\n\u001b[1;32m     <a href='vscode-notebook-cell:/c%3A/code/mlfromjax/nn/01.%20NN%20discriminative.ipynb#X42sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m         x \u001b[39m=\u001b[39m x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias\n",
      "    \u001b[0;31m[... skipping hidden 12 frame]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/jax-py310/lib/python3.10/site-packages/jax/_src/numpy/lax_numpy.py:3101\u001b[0m, in \u001b[0;36mdot\u001b[0;34m(a, b, precision, preferred_element_type)\u001b[0m\n\u001b[1;32m   3099\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   3100\u001b[0m     contract_dims \u001b[39m=\u001b[39m ((a_ndim \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m,), (b_ndim \u001b[39m-\u001b[39m \u001b[39m2\u001b[39m,))\n\u001b[0;32m-> 3101\u001b[0m   result \u001b[39m=\u001b[39m lax\u001b[39m.\u001b[39;49mdot_general(a, b, dimension_numbers\u001b[39m=\u001b[39;49m(contract_dims, batch_dims),\n\u001b[1;32m   3102\u001b[0m                            precision\u001b[39m=\u001b[39;49mprecision, preferred_element_type\u001b[39m=\u001b[39;49mpreferred_element_type)\n\u001b[1;32m   3103\u001b[0m \u001b[39mreturn\u001b[39;00m lax_internal\u001b[39m.\u001b[39m_convert_element_type(result, preferred_element_type, output_weak_type)\n",
      "    \u001b[0;31m[... skipping hidden 7 frame]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/jax-py310/lib/python3.10/site-packages/jax/_src/lax/lax.py:2557\u001b[0m, in \u001b[0;36m_dot_general_shape_rule\u001b[0;34m(lhs, rhs, dimension_numbers, precision, preferred_element_type)\u001b[0m\n\u001b[1;32m   2554\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m core\u001b[39m.\u001b[39mdefinitely_equal_shape(lhs_contracting_shape, rhs_contracting_shape):\n\u001b[1;32m   2555\u001b[0m   msg \u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39mdot_general requires contracting dimensions to have the same \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2556\u001b[0m          \u001b[39m\"\u001b[39m\u001b[39mshape, got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 2557\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(msg\u001b[39m.\u001b[39mformat(lhs_contracting_shape, rhs_contracting_shape))\n\u001b[1;32m   2559\u001b[0m \u001b[39mreturn\u001b[39;00m _dot_general_shape_computation(lhs\u001b[39m.\u001b[39mshape, rhs\u001b[39m.\u001b[39mshape, dimension_numbers)\n",
      "\u001b[0;31mTypeError\u001b[0m: dot_general requires contracting dimensions to have the same shape, got (10,) and (8,)."
     ]
    }
   ],
   "source": [
    "x_batch = jax.random.normal(key, (8, 10))  # batch_size = 8\n",
    "layer1(x_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We hit our first issue here, the forward pass in the function is defined to work with a single input example.\n",
    "\n",
    "That's where we use the handy jax auto-vectorization function `vmap`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 2)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.vmap(layer1)(x_batch).shape  # works as expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we're ready to create a skeleton of our toy NN library: `toylib`!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
